{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "import pandas\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using cuda: NVIDIA GeForce RTX 3090\n"
     ]
    }
   ],
   "source": [
    "# check if CUDA is available\n",
    "# if yes, set default tensor type to cuda\n",
    "\n",
    "torch.cuda.set_device(7)\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "  torch.set_default_tensor_type(torch.cuda.FloatTensor)\n",
    "  print(\"using cuda:\", torch.cuda.get_device_name(0))\n",
    "\n",
    "# device = torch.device(\"cuda:7\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda', index=7)"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.tensor([1.2, 3]).device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset class\n",
    "\n",
    "class MnistDataset(Dataset):\n",
    "    \n",
    "    def __init__(self, csv_file):\n",
    "        self.data_df = pandas.read_csv(csv_file, header=None)\n",
    "        pass\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.data_df)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        # image target (label)\n",
    "        label = self.data_df.iloc[index,0]\n",
    "        target = torch.zeros((10))\n",
    "        target[label] = 1.0\n",
    "        \n",
    "        # image data, normalised from 0-255 to 0-1\n",
    "        image_values = torch.tensor(self.data_df.iloc[index,1:].values) / 255.0\n",
    "        \n",
    "        # return label, image data tensor and target tensor\n",
    "        return label, image_values, target\n",
    "    \n",
    "    def plot_image(self, index):\n",
    "        img = self.data_df.iloc[index,1:].values.reshape(28,28)\n",
    "        plt.title(\"label = \" + str(self.data_df.iloc[index,0]))\n",
    "        plt.imshow(img, interpolation='none', cmap='Blues')\n",
    "        pass\n",
    "    \n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist_dataset = MnistDataset(\"mnist_train.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5,\n",
       " tensor([0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0118,\n",
       "         0.0706, 0.0706, 0.0706, 0.4941, 0.5333, 0.6863, 0.1020, 0.6510, 1.0000,\n",
       "         0.9686, 0.4980, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.1176, 0.1412, 0.3686, 0.6039,\n",
       "         0.6667, 0.9922, 0.9922, 0.9922, 0.9922, 0.9922, 0.8824, 0.6745, 0.9922,\n",
       "         0.9490, 0.7647, 0.2510, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.1922, 0.9333, 0.9922, 0.9922,\n",
       "         0.9922, 0.9922, 0.9922, 0.9922, 0.9922, 0.9922, 0.9843, 0.3647, 0.3216,\n",
       "         0.3216, 0.2196, 0.1529, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0706, 0.8588, 0.9922,\n",
       "         0.9922, 0.9922, 0.9922, 0.9922, 0.7765, 0.7137, 0.9686, 0.9451, 0.0000,\n",
       "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.3137,\n",
       "         0.6118, 0.4196, 0.9922, 0.9922, 0.8039, 0.0431, 0.0000, 0.1686, 0.6039,\n",
       "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000, 0.0549, 0.0039, 0.6039, 0.9922, 0.3529, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000, 0.0000, 0.0000, 0.0000, 0.5451, 0.9922, 0.7451, 0.0078, 0.0000,\n",
       "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0431, 0.7451, 0.9922, 0.2745,\n",
       "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.1373, 0.9451,\n",
       "         0.8824, 0.6275, 0.4235, 0.0039, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.3176, 0.9412, 0.9922, 0.9922, 0.4667, 0.0980, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000, 0.0000, 0.1765, 0.7294, 0.9922, 0.9922, 0.5882, 0.1059, 0.0000,\n",
       "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000, 0.0000, 0.0000, 0.0000, 0.0627, 0.3647, 0.9882, 0.9922, 0.7333,\n",
       "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.9765, 0.9922,\n",
       "         0.9765, 0.2510, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.1804, 0.5098, 0.7176, 0.9922,\n",
       "         0.9922, 0.8118, 0.0078, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000, 0.0000, 0.0000, 0.0000, 0.1529, 0.5804, 0.8980, 0.9922, 0.9922,\n",
       "         0.9922, 0.9804, 0.7137, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000, 0.0000, 0.0000, 0.0941, 0.4471, 0.8667, 0.9922, 0.9922, 0.9922,\n",
       "         0.9922, 0.7882, 0.3059, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000, 0.0000, 0.0902, 0.2588, 0.8353, 0.9922, 0.9922, 0.9922, 0.9922,\n",
       "         0.7765, 0.3176, 0.0078, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000, 0.0706, 0.6706, 0.8588, 0.9922, 0.9922, 0.9922, 0.9922, 0.7647,\n",
       "         0.3137, 0.0353, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.2157, 0.6745, 0.8863, 0.9922, 0.9922, 0.9922, 0.9922, 0.9569, 0.5216,\n",
       "         0.0431, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000, 0.5333, 0.9922, 0.9922, 0.9922, 0.8314, 0.5294, 0.5176, 0.0627,\n",
       "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
       "         0.0000]),\n",
       " tensor([0., 0., 0., 0., 0., 1., 0., 0., 0., 0.]))"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnist_dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "mnist_dataset.plot_image(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "# classifier class\n",
    "\n",
    "class Classifier(nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        # initialise parent pytorch class\n",
    "        super().__init__()\n",
    "        \n",
    "        # define neural network layers\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Linear(784, 200),\n",
    "            nn.Sigmoid(),\n",
    "            nn.Linear(200, 10),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "        \n",
    "        # create loss function\n",
    "        self.loss_function = nn.MSELoss()\n",
    "\n",
    "        # create optimiser, using simple stochastic gradient descent\n",
    "        self.optimiser = torch.optim.SGD(self.parameters(), lr=0.01)\n",
    "\n",
    "        # counter and accumulator for progress\n",
    "        self.counter = 0\n",
    "        self.progress = []\n",
    "\n",
    "        pass\n",
    "    \n",
    "    \n",
    "    def forward(self, inputs):\n",
    "        # simply run model\n",
    "        return self.model(inputs)\n",
    "    \n",
    "    \n",
    "    def train(self, inputs, targets):\n",
    "        # calculate the output of the network\n",
    "        outputs = self.forward(inputs)\n",
    "        \n",
    "        # calculate loss\n",
    "        loss = self.loss_function(outputs, targets)\n",
    "\n",
    "        # increase counter and accumulate error every 10\n",
    "        self.counter += 1\n",
    "        if (self.counter % 10 == 0):\n",
    "            self.progress.append(loss.item())\n",
    "            pass\n",
    "        if (self.counter % 10000 == 0):\n",
    "            print(\"counter = \", self.counter)\n",
    "            pass\n",
    "\n",
    "        # zero gradients, perform a backward pass, and update the weights\n",
    "        self.optimiser.zero_grad()\n",
    "        loss.backward()\n",
    "        self.optimiser.step()\n",
    "\n",
    "        pass\n",
    "    \n",
    "    \n",
    "    def plot_progress(self):\n",
    "        df = pandas.DataFrame(self.progress, columns=['loss'])\n",
    "        df.plot(ylim=(0, 1.0), figsize=(16,8), alpha=0.1, marker='.', grid=True, yticks=(0, 0.25, 0.5))\n",
    "        pass\n",
    "    \n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training epoch 1 of 4\n",
      "counter =  10000\n",
      "counter =  20000\n",
      "counter =  30000\n",
      "counter =  40000\n",
      "counter =  50000\n",
      "counter =  60000\n",
      "training epoch 2 of 4\n",
      "counter =  70000\n",
      "counter =  80000\n",
      "counter =  90000\n",
      "counter =  100000\n",
      "counter =  110000\n",
      "counter =  120000\n",
      "training epoch 3 of 4\n",
      "counter =  130000\n",
      "counter =  140000\n",
      "counter =  150000\n",
      "counter =  160000\n",
      "counter =  170000\n",
      "counter =  180000\n",
      "training epoch 4 of 4\n",
      "counter =  190000\n",
      "counter =  200000\n",
      "counter =  210000\n",
      "counter =  220000\n",
      "counter =  230000\n",
      "counter =  240000\n",
      "CPU times: user 3min 55s, sys: 2.94 s, total: 3min 58s\n",
      "Wall time: 3min 57s\n"
     ]
    }
   ],
   "source": [
    "%%time \n",
    "# create neural network\n",
    "\n",
    "C = Classifier()\n",
    "\n",
    "# train network on MNIST data set\n",
    "\n",
    "epochs = 4\n",
    "\n",
    "for i in range(epochs):\n",
    "    print('training epoch', i+1, \"of\", epochs)\n",
    "    for label, image_data_tensor, target_tensor in mnist_dataset:\n",
    "        C.train(image_data_tensor, target_tensor)\n",
    "        pass\n",
    "    pass\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6.5 ('snow')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "7b4ed43ba748000add0b3d5b8442bed2bd4789ba31db7f02b28d7a0fd44e667d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
